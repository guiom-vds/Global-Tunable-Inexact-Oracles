{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# :: Tunable First-Order Inexact Oracles (TFOIO) ::\n",
    "`Performance analysis of deterministic gradient based methods using (global) tunable first-order inexact oracles.`\n",
    "\n",
    "**Author** : *Guillaume Van Dessel*, Ph.D. candidate @EPL\n",
    "\n",
    "**Version** : 2.0 | working version for $d_p$=1\n",
    "\n",
    "**Comment** : For now on, let's stick to fully deterministic methods (however those might be inexact as well but there must be \n",
    "no source of randomness at each update step apart from oracle's content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## packages' import\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import pandas as pd\n",
    "from scipy.stats import wald,norm,f,expon,chi2,uniform\n",
    "import scipy.linalg as scla\n",
    "from IPython.display import display,clear_output\n",
    "from ipywidgets import *\n",
    "import decimal\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='epl.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a problem\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @instantiation of the possibility lists \n",
    "\n",
    "# objective function list\n",
    "obj_list = ['generic','other'] # add practical things\n",
    "\n",
    "# search space dimension \n",
    "d = 10\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "# @creation of inherent widgets\n",
    "\n",
    "widget_obj = widgets.Dropdown(\n",
    "    options=obj_list,\n",
    "    value=obj_list[0],\n",
    "    description='obj. fun.: ',\n",
    ")\n",
    "\n",
    "widget_d = widgets.IntSlider(\n",
    "    value=d,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='dimension:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "widget_cons = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='constrained?',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widget_distance = BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=1000.0,\n",
    "    step=0.05,\n",
    "    description='center norm:',\n",
    "    disabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @default Problem class\n",
    "class Problem:\n",
    "    \n",
    "    f = lambda x: (1/2)*np.sum(x**2)\n",
    "    dif_f = lambda x: x\n",
    "    mu = 1\n",
    "    L = 1\n",
    "    d = 10\n",
    "    m = 0\n",
    "    constr = False\n",
    "    x_star = np.zeros(d)\n",
    "    scale = 5\n",
    "    center = None\n",
    "    type_dom = None\n",
    "    update = lambda h,u: u\n",
    "    \n",
    "def short_not(float_number):\n",
    "    return '%.3e' % decimal.Decimal(str(float_number))\n",
    "    \n",
    "def present_Problem():\n",
    "    \n",
    "    print(' ')\n",
    "    print('|| problem summary ||')\n",
    "    print('---------------------')\n",
    "    print(' ')\n",
    "    if Problem.constr:\n",
    "        if Problem.type_dom is 'box':\n",
    "            print('=> constrained in a box defined by :')\n",
    "            if Problem.d <= 5:\n",
    "                buf='['+short_not(Problem.center[0]-Problem.scale)+' , '+short_not(Problem.center[0]+Problem.scale)+']'\n",
    "                for elem in np.linspace(1,Problem.d-1,Problem.d-1):\n",
    "                    buf+=' X ['+short_not(Problem.center[int(elem)]-Problem.scale)+' , '\\\n",
    "                    +short_not(Problem.center[int(elem)]+Problem.scale)+']'\n",
    "            else:\n",
    "                buf = 'U from i = 1 to '+str(Problem.d)+' [c_i - '+str(Problem.scale)+' , c_i + '+str(Problem.scale)+']'\n",
    "            print(buf)\n",
    "        else:\n",
    "            print('=> constrainted in a ball defined by : ')\n",
    "            print(' B := {x in R^'+str(int(Problem.d))+' | ||x-c|| <= '+str(Problem.scale)+'}')\n",
    "    else: \n",
    "        print('=> unconstrained ')\n",
    "    print(' ')\n",
    "    print('dimension : '+str(int(Problem.d)))\n",
    "    print('estimated strong convexity parameter : '+str(Problem.mu))\n",
    "    print('estimated smoothness parameter : '+str(Problem.L))\n",
    "    print('activated constraints at optimum : '+str(int(Problem.m)))\n",
    "    if Problem.d <= 20:\n",
    "        print('optimum : '+str(Problem.x_star))\n",
    "    print(' ')\n",
    "    \n",
    "def reset_Problem():\n",
    "    \n",
    "    Problem.f = lambda x: (1/2)*np.sum((x-Problem.x_star)**2)\n",
    "    Problem.f = lambda x: (x-Problem.x_star)\n",
    "    Problem.mu = 1\n",
    "    Problem.L = 1\n",
    "    Problem.d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models x_*\n",
    "def free(dist):\n",
    "    \n",
    "    direc = norm.rvs(loc=0, scale=1, size=Problem.d)\n",
    "    Problem.x_star = dist*direc/scla.norm(direc)\n",
    "    \n",
    "    Problem.center = Problem.x_star\n",
    "    \n",
    "    print(' ')\n",
    "    print('=> a new optimizer has been chosen')\n",
    "    if Problem.d <= 20:\n",
    "        print(Problem.x_star)\n",
    "    print(' ')\n",
    "    \n",
    "def ball_proj(u,center,scale):\n",
    "    return center + (u-center)/np.max([scale,scla.norm(u-center)])\n",
    "    \n",
    "def ball_constraint(center,m,scale):\n",
    "    \n",
    "    Problem.m = m\n",
    "    Problem.scale = scale\n",
    "    Problem.update = lambda h,u: ball_proj(u,Problem.center,Problem.scale)\n",
    "    \n",
    "    direc = norm.rvs(loc=0, scale=1, size=Problem.d)\n",
    "    \n",
    "    if m==1:\n",
    "        Problem.x_star = center+scale*direc/scla.norm(direc)\n",
    "    else:\n",
    "        Problem.x_star = center+(scale*np.random.uniform(0,1)**(1/Problem.d))*direc/scla.norm(direc)\n",
    "        \n",
    "    print(' ')\n",
    "    print('=> a new optimizer has been chosen')\n",
    "    if Problem.d <= 20:\n",
    "        print(Problem.x_star)\n",
    "    print(' ')\n",
    "    \n",
    "def box_proj(u,center,scale):\n",
    "    buf = []\n",
    "    bounds = [center-scale,center+scale]\n",
    "    for j in np.arange(len(u)):\n",
    "        if u[j]<bounds[0][j]:\n",
    "            buf.append(bounds[0][j])\n",
    "        elif u[j]>bounds[1][j]:\n",
    "            buf.append(bounds[1][j])\n",
    "        else:\n",
    "            buf.append(u[j])\n",
    "    return np.array(buf)\n",
    "        \n",
    "def box_constraint(center,m,scale):\n",
    "    \n",
    "    Problem.m = m\n",
    "    Problem.scale = scale\n",
    "    Problem.update = lambda h,u: box_proj(u,Problem.center,Problem.scale)\n",
    "    \n",
    "    bounds = [center-Problem.scale,center+Problem.scale]\n",
    "    \n",
    "    if m>0:\n",
    "        indices = np.random.choice(np.arange(Problem.d),m,False)\n",
    "        buf = np.zeros(Problem.d)\n",
    "        for elem in np.arange(Problem.d):\n",
    "            if elem in indices:\n",
    "                buf[elem] = np.random.choice([bounds[0][elem],bounds[1][elem]],1)[0]\n",
    "            else:\n",
    "                buf[elem] = np.random.uniform(bounds[0][elem],bounds[1][elem],1)\n",
    "        Problem.x_star = buf\n",
    "    else:\n",
    "        Problem.x_star = np.random.uniform(bounds[0],bounds[1],Problem.d)\n",
    "        \n",
    "    print(' ')\n",
    "    print('=> a new optimizer has been chosen')\n",
    "    if Problem.d <= 20:\n",
    "        print(Problem.x_star)\n",
    "    print(' ')\n",
    "    \n",
    "def constraint(dist,cstr_type='box'):\n",
    "    \n",
    "    direc = norm.rvs(loc=0, scale=1, size=Problem.d)\n",
    "    cent = dist*direc/scla.norm(direc)\n",
    "    \n",
    "    Problem.center = cent\n",
    "    \n",
    "    widget_scale = BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=1000.0,\n",
    "    step=0.05,\n",
    "    description='scale:',\n",
    "    disabled=False)\n",
    "    \n",
    "    if cstr_type is 'ball':\n",
    "        \n",
    "        Problem.type_dom = 'ball'\n",
    "    \n",
    "        widget_m = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=1,\n",
    "        step=1,\n",
    "        description='number of activated constraints at x_*:')\n",
    "        \n",
    "        interact(lambda m,scale: ball_constraint(cent,m,scale),m=widget_m,scale=widget_scale)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Problem.type_dom = 'box'\n",
    "        \n",
    "        widget_m = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=Problem.d,\n",
    "        step=1,\n",
    "        description='number of activated constraints at x_*:')\n",
    "        \n",
    "        interact(lambda m,scale: box_constraint(cent,m,scale),m=widget_m,scale=widget_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models for f and del f\n",
    "\n",
    "# generic\n",
    "def generic(alpha=0.1,beta=1.25,gamma=9.8):\n",
    "    \n",
    "    # @priori s.c. and smoothness parameters\n",
    "    Problem.mu = alpha\n",
    "    Problem.L = alpha + 4*beta + gamma/2 \n",
    "    \n",
    "    def z(x):\n",
    "        return (1/2)*np.sum(x**2)\n",
    "    \n",
    "    def grad_z(x):\n",
    "        return x\n",
    "    \n",
    "    def g(x):\n",
    "        return (1/2)*(x[0]**2 + x[-1]**2 + np.sum((x[:-1]-x[1:])**2))\n",
    "    \n",
    "    def grad_g(x):\n",
    "        zer = np.zeros(1)\n",
    "        _x = np.concatenate((zer,x[:-1]),axis=None)\n",
    "        x_ = np.concatenate((x[1:],zer),axis=None)\n",
    "        return 2*x - (_x + x_)\n",
    "    \n",
    "    def h(x):\n",
    "        delta = np.max(x)\n",
    "        return delta + np.log(np.sum(np.exp(x-delta)))\n",
    "    \n",
    "    def grad_h(x):\n",
    "        delta = np.max(x)\n",
    "        u = np.exp(x-delta)\n",
    "        return u/np.sum(u)\n",
    "    \n",
    "    x_star = Problem.x_star\n",
    "    h_star = h(x_star)\n",
    "    grad_h_star = grad_h(x_star)\n",
    "    \n",
    "    # first order information\n",
    "    \n",
    "    Problem.f = lambda x: alpha*z(x-x_star) + beta*g(x-x_star) +\\\n",
    "            gamma*(h(x)-h_star-(grad_h_star@(x-x_star)))\n",
    "    \n",
    "    Problem.dif_f = lambda x: alpha*grad_z(x-x_star) + beta*grad_g(x-x_star)+\\\n",
    "            gamma*(grad_h(x)-grad_h_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aux. methods\n",
    "\n",
    "def change_optimizer(dimension,boolean,distance=5):\n",
    "    \n",
    "    Problem.d = int(dimension)\n",
    "    Problem.constr = boolean\n",
    "    \n",
    "    if boolean: # only box, ball\n",
    "        \n",
    "        widget_type = widgets.Dropdown(\n",
    "        options=['box','ball'],\n",
    "        value='box',\n",
    "        description='constraint type: ')\n",
    "        \n",
    "        interact(lambda cstr_type: constraint(distance,cstr_type), cstr_type = widget_type)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        free(distance)\n",
    "        \n",
    "\n",
    "def change_obj(string):\n",
    "    \n",
    "    if string is 'generic':\n",
    "        \n",
    "        yf = widgets.HTMLMath(value=r'$$f(x) = \\frac{\\alpha}{2}\\,||x-x_*||^2 + \\beta \\, g(x-x_*) + \\gamma \\, [h(x) - h(x_*) \\\n",
    "        - \\langle \\nabla h(x_*) \\, , \\, x-x_* \\rangle] $$')\n",
    "        ye = widgets.Label(value='where')\n",
    "        yg = widgets.HTMLMath(value=r'$$g(x) = \\frac{1}{2}\\,[x_{1}^2 + \\sum_{i=1}^{d}\\, (x_{i} - x_{i+1})^2 + x_{d}^2]$$')\n",
    "        yh = widgets.HTMLMath(value=r'$$h(x) = \\log(\\sum_{i=1}^{d} \\, e^{x_{i}})$$')\n",
    "        display(yf,ye,yg,yh)\n",
    "        \n",
    "        widget_alpha = BoundedFloatText(\n",
    "            value=0.1,\n",
    "            min=0,\n",
    "            max=100.0,\n",
    "            step=0.01,\n",
    "            description='alpha:',\n",
    "            disabled=False)\n",
    "        \n",
    "        widget_beta = BoundedFloatText(\n",
    "            value=1.25,\n",
    "            min=0,\n",
    "            max=100000.0,\n",
    "            step=0.05,\n",
    "            description='beta:',\n",
    "            disabled=False)\n",
    "        \n",
    "        widget_gamma = BoundedFloatText(\n",
    "            value=9.8,\n",
    "            min=0,\n",
    "            max=500000.0,\n",
    "            step=0.2,\n",
    "            description='gamma:',\n",
    "            disabled=False)\n",
    "        \n",
    "        # exact f,dif functions \n",
    "        interact(generic,alpha = widget_alpha,beta = widget_beta, gamma = widget_gamma);\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # default f,dif functions \n",
    "        reset_Problem()\n",
    "        y = widgets.HTMLMath(value=r'$$f(x) = \\frac{||x-x_*||^2}{2}$$')\n",
    "        display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimum \n",
    "interact(change_optimizer,dimension = widget_d,boolean = widget_cons, distance = widget_distance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "interact(change_obj,string = widget_obj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = widgets.Button(description=\"Load Problem\")\n",
    "output = widgets.Output()\n",
    "\n",
    "display(button, output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        present_Problem()\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy-to-go results \n",
    "------------------------------\n",
    "\n",
    "Using *Devolder* type first-order tunable inexact oracles with fixed $\\mu \\leq L$, i.e. $\\mathcal{T}_k = (\\delta(\\eta_k),L,\\mu)$, $\\forall k \\in \\{0,\\dots,N-1\\}$, one can show that \n",
    "\n",
    "$$ f(\\hat{x}_N) - f^* \\leq \\frac{LR^2 \\gamma_N}{2 W_N} + \\frac{\\sum_{k=0}^{N-1} w_k\\, \\delta(\\eta_k)}{W_N}$$\n",
    "\n",
    "where the coefficients $\\gamma_N$, $\\{w_k\\}_{k=0}^{N-1}$ and $W_N$ are defined for every $N \\in \\mathbb{N}$ as in the following table.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\\begin{eqnarray}\n",
    "          & & \\gamma_N & w_k & W_{N} \\\\\n",
    "     -----& -----|& ------& ------& -----\\\\\n",
    "\\text{GD} & & \\rho^N & \\rho^{N-1-k} & \\sum_{k=0}^{N-1} \\rho^{N-1-k} \\\\\n",
    "\\text{FGD} & & 1 & A_k & A_{N-1} \\\\\n",
    "\\end{eqnarray}\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "where $A_k = \\sum_{i=0}^k \\alpha_k$ for which a reccurence is set up : $\\alpha_0 \\in ]0,1], \\hspace{2pt} L+\\mu\\,A_k \\geq \\frac{L\\alpha_{k+1}^2}{A_{k+1}}$ and $\\rho = (1-\\frac{\\mu}{L})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of a model\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic delta model\n",
    "------------------------------------------------------\n",
    "\n",
    "\n",
    " $$ \\delta(\\eta_k) = q\\frac{\\eta_k^j}{j}$$\n",
    " \n",
    " Do not forget that $\\ell_a \\succeq \\mathbf{0}$ in order to ensure convexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 2\n",
    "mult_i = 3\n",
    "mult_ii = (2*Problem.L + Problem.mu)/(Problem.L*Problem.mu) # Problem.mu should be strictly positive\n",
    "\n",
    "def delta_i(eta):\n",
    "    return mult_i*eta**j / j\n",
    "\n",
    "def delta_ii(eta):\n",
    "    return mult_ii*e**j / j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic cost models\n",
    "------------------------------------------------------\n",
    "\n",
    "for all $k \\in \\{0,...,N-1\\}$,\n",
    "\n",
    " (i)$$ \\mathcal{M}_k(\\eta_k) = K + \\frac{\\beta}{(\\eta_k)^r}$$\n",
    " (ii) $$ \\mathcal{M}_k(\\eta_k) = K - \\beta \\log(\\eta_k) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 < c3*c2 to avoid convexity issues in (c1*delta + c2)/(1+c3*delta)\n",
    "scaler_i = 1e-8\n",
    "scaler_ii = 0.75\n",
    "r = 1\n",
    "K = 1\n",
    "la = 2e-6\n",
    "lb = 1e-2\n",
    "la_exp = int(np.log10(la))\n",
    "lb_exp = int(np.log10(lb))\n",
    "beta_i = 1e3\n",
    "beta_ii = 1/np.log(1/la)\n",
    "\n",
    "\n",
    "def base_cost_i(eta):\n",
    "    return scaler_i*(K+beta_i/(eta)**r)\n",
    "\n",
    "def total_cost_i(etas):\n",
    "    return scaler_i*(len(etas)*K + beta_i*np.sum(1/(+etas)**r))\n",
    "\n",
    "def diff_total_cost_i(etas):\n",
    "    return scaler_i*(-r*beta_i/(etas)**(r+1))\n",
    "\n",
    "def base_cost_ii(eta):\n",
    "    return scaler_ii*(K-beta_ii*np.log(eta))\n",
    "\n",
    "def total_cost_i(etas):\n",
    "    return scaler_ii*(len(etas)*K - beta_ii*np.sum(np.log(etas)))\n",
    "\n",
    "def diff_total_cost_i(etas):\n",
    "    return scaler_ii*(-beta_ii/(etas))\n",
    "\n",
    "\n",
    "etas = np.logspace(la_exp,lb_exp,200)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.title('Visualization of inexact-oracle''s cost')\n",
    "plt.xlabel('$\\eta$')\n",
    "plt.ylabel('$\\mathcal{M}(\\eta)$')\n",
    "plt.grid()\n",
    "plt.semilogx(etas,base_cost_i(etas))\n",
    "plt.semilogx(etas,base_cost_ii(etas))\n",
    "plt.legend(['(1) inv. prop. based','(2) log based']);\n",
    "plt.savefig('costs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gamma_N / w_k / W_N (+ alpha_k in full mode turned on True and in 'FGD')\n",
    "\n",
    "def compute_serial_coeffs(N=100,L=4,mu=0.01,mode = 'GD', full=False):\n",
    "    if mode=='FGD':\n",
    "        a_0 = 1 # shouldn't be changed\n",
    "        a_list = [a_0]\n",
    "        A = a_0\n",
    "        A_list = [a_0]\n",
    "        for k in np.arange(1,N):\n",
    "            base = (L+mu*A)/L \n",
    "            buf = (base+np.sqrt(base**2 + 4*base*A))/2\n",
    "            a_list.append(buf)\n",
    "            A += buf\n",
    "            A_list.append(A)\n",
    "        ret = np.array(A_list)\n",
    "        if full:\n",
    "            return 1,ret,ret[-1],np.array(a_list)\n",
    "        else:\n",
    "            return 1,ret,ret[-1]\n",
    "    else:\n",
    "        N_list = np.arange(N)\n",
    "        rho = (1-mu/L)\n",
    "        ret = rho**(N-1-N_list)\n",
    "        return rho**N,ret,np.sum(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-opt as recomputation of coefficients gamma_N,w_k's, ... etc\n",
    "def N_lower(L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,la=5e-7,verbose=False):\n",
    "    \n",
    "    # params\n",
    "    delta_fun = lambda eta: (q/j)*eta**(j)\n",
    "    N_max_default = int(1e4)\n",
    "    mult = 2\n",
    "    N_min = int(1)\n",
    "    N_current = N_min\n",
    "    non_feas = True\n",
    "    \n",
    "    # find better suitable N_max\n",
    "    while (non_feas and N_current < N_max_default):\n",
    "        N_current = np.floor(N_current*mult)\n",
    "        gamma_N,w_k,W_N = compute_serial_coeffs(int(N_current),L,mu,mode)\n",
    "        Gamma_N_eps = W_N*epsilon - (gamma_N*L*R**2)/2\n",
    "        non_feas = (Gamma_N_eps - np.sum(w_k)*delta_fun(la))<0\n",
    "        \n",
    "    N_max = np.min([N_current,N_max_default])\n",
    "    if verbose:\n",
    "        print('bounds found at for N_min: ['+str(int(N_min))+', '+str(int(N_max))+']')\n",
    "    \n",
    "    # bisection \n",
    "    while N_max-N_min>1:\n",
    "        N_current = np.floor((N_max+N_min)/2)\n",
    "        gamma_N,w_k,W_N = compute_serial_coeffs(int(N_current),L,mu,mode)\n",
    "        Gamma_N_eps = W_N*epsilon - (gamma_N*L*R**2)/2\n",
    "        feas = (Gamma_N_eps - np.sum(w_k)*delta_fun(la))>=0\n",
    "        if feas:\n",
    "            N_max = N_current\n",
    "        else:\n",
    "            N_min = N_current\n",
    "            \n",
    "    if verbose:\n",
    "        print('final estimation for N_min: '+str(int(N_max)))\n",
    "    return int(N_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @default Instance class\n",
    "class Instance:\n",
    "    \n",
    "    cost_model = 'inv_prop'\n",
    "    met = 'FGD'\n",
    "    q = 1\n",
    "    K = 1e3\n",
    "    beta = 1\n",
    "    r = 1\n",
    "    j = 1\n",
    "    epsilon = 5e-5\n",
    "    N = 150\n",
    "    la = 5e-7\n",
    "    lb = 1e-3\n",
    "    R = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change2_obj(cm,met,q,K,beta2,r,j,epsilon,N,la,lb,R):\n",
    "    \n",
    "    delta_fun = lambda eta: (q/j)*eta**(j)\n",
    "    gamma_N,w_k,W_N = compute_serial_coeffs(N,Problem.L,Problem.mu,met)\n",
    "    Gamma_N_eps = W_N*epsilon - (gamma_N*Problem.L*R**2)/2\n",
    "    rest = np.sum(w_k)*delta_fun(la)\n",
    "    if Gamma_N_eps>rest:\n",
    "        print(' preview ok => Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(rest))\n",
    "    else:\n",
    "        print(' preview not ok => Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(rest))\n",
    "\n",
    "    Instance.cost_model = cm\n",
    "    Instance.met = met\n",
    "    Instance.q = q\n",
    "    Instance.K = K\n",
    "    Instance.beta = beta2\n",
    "    Instance.r = r\n",
    "    Instance.j = j\n",
    "    Instance.epsilon = epsilon\n",
    "    Instance.N = N\n",
    "    Instance.la = la\n",
    "    Instance.lb = lb\n",
    "    Instance.R = R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @instantiation of the possibility lists \n",
    "\n",
    "# cost model list\n",
    "cost_model_list = ['inv_prop','minus_log'] # add practical things\n",
    "\n",
    "# method list\n",
    "met_list = ['FGD','GD']\n",
    "\n",
    "# inaccuracy level distribution list\n",
    "dst_list = ['uniform','exponential','F','chi2','wald']\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "# @creation of inherent widgets\n",
    "\n",
    "widget_cost_model = widgets.Dropdown(\n",
    "    options=cost_model_list,\n",
    "    value=cost_model_list[0],\n",
    "    description='cost model: ',\n",
    ")\n",
    "\n",
    "widget_met = widgets.Dropdown(\n",
    "    options=met_list,\n",
    "    value=met_list[0],\n",
    "    description='method: ',\n",
    ")\n",
    "\n",
    "widget_dst = widgets.Dropdown(\n",
    "    options=dst_list,\n",
    "    value=dst_list[0],\n",
    "    description='distrib. level: ',\n",
    ")\n",
    "\n",
    "widget_epsilon = BoundedFloatText(\n",
    "    value=1e-5,\n",
    "    min=1e-10,\n",
    "    max=1,\n",
    "    step=1e-6,\n",
    "    description='epsilon:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_N =widgets.BoundedIntText(\n",
    "    value=151,\n",
    "    min=1,\n",
    "    max=10000,\n",
    "    step=5,\n",
    "    description='N:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widget_K = BoundedFloatText(\n",
    "    value=1000,\n",
    "    min=0,\n",
    "    max=10000.0,\n",
    "    step=1,\n",
    "    description='K:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_R = BoundedFloatText(\n",
    "    value=10,\n",
    "    min=0,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='R:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_q = BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.01,\n",
    "    description='q:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_beta2 = BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.001,\n",
    "    description='beta:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_r = BoundedFloatText(\n",
    "    value=1.0,\n",
    "    min=0,\n",
    "    max=100.0,\n",
    "    step=0.5,\n",
    "    description='r:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_j = BoundedFloatText(\n",
    "    value=1.0,\n",
    "    min=0,\n",
    "    max=100.0,\n",
    "    step=0.5,\n",
    "    description='j:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_la = BoundedFloatText(\n",
    "    value=5e-7,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1e-8,\n",
    "    description='la:',\n",
    "    disabled=False)\n",
    "\n",
    "widget_lb = BoundedFloatText(\n",
    "    value=1e-3,\n",
    "    min=0,\n",
    "    max=100000,\n",
    "    step=1e-8,\n",
    "    description='lb:',\n",
    "    disabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(change2_obj,cm=widget_cost_model,met=widget_met,q=widget_q,K=widget_K,beta2=widget_beta2,r=widget_r,j=widget_j,\\\n",
    "        epsilon=widget_epsilon,N=widget_N,la=widget_la,lb=widget_lb,R=widget_R);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_to_N_min():\n",
    "    N_min  = N_lower(Problem.L,Problem.mu,Instance.met,Instance.epsilon,Instance.R,Instance.j,Instance.q,Instance.la,False)\n",
    "    Instance.N = N_min\n",
    "    widget_N.value = N_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_N = widgets.Button(description=\"Set N <- N_min\")\n",
    "output_N = widgets.Output()\n",
    "\n",
    "display(button_N, output_N)\n",
    "\n",
    "def on_button_clicked_N(b):\n",
    "    with output_N:\n",
    "        set_to_N_min()\n",
    "\n",
    "button_N.on_click(on_button_clicked_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitioner(N,conv_term=1e-5,error_term=2e-5):\n",
    "\n",
    "    repartition = [conv_term,error_term]\n",
    "    repartition.append(np.sum(repartition))\n",
    "    sources = np.arange(len(repartition))\n",
    "    \n",
    "    print('percentages : conv term <- '+str(conv_term/(conv_term+error_term))+' , error term <- '+str(error_term/(conv_term+error_term)))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.grid(axis='y')\n",
    "    barlist = plt.bar(sources,repartition)\n",
    "    plt.title('Repartition of the accuracy for N = '+str(int(N)))\n",
    "    plt.xticks(sources, ('Convergence Term', 'Error Term','Target Accuracy'))\n",
    "    barlist[0].set_color('orange')\n",
    "    barlist[1].set_color('red')\n",
    "    barlist[2].set_color('blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_i_imp(N=151,L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,r=1,la=5e-7,lb=1e-3,beta=1,display=True):\n",
    "    N_list = np.arange(N+1)\n",
    "    delta_fun = lambda eta: (q/j)*eta**(j)\n",
    "    gamma_N,w_k,W_N = compute_serial_coeffs(N,L,mu,mode)\n",
    "    Gamma_N_eps = W_N*epsilon - (gamma_N*L*R**2)/2\n",
    "    check_feas = (Gamma_N_eps - np.sum(w_k)*delta_fun(la) >= 0) # check feasibility\n",
    "    if check_feas==False:\n",
    "        if display:\n",
    "            print(' => error infeasible || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "    else: # lin-search\n",
    "        if display:\n",
    "            print(' => experiment started || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "        Na_list = np.arange(N+1)\n",
    "        Nb_list = np.arange(N+1)\n",
    "        NA,NB = np.meshgrid(Na_list,Nb_list)\n",
    "        lambda_0_opt_hat_mesh = []\n",
    "        lambda_0_max = 0\n",
    "        Na_best,Nb_best = 0,0\n",
    "        Na_best0 = 0\n",
    "        lambda_0_max0 = 0\n",
    "        ok_counter = 0\n",
    "        ok_NaNb = []\n",
    "        \n",
    "        # clear version (not optimized though)\n",
    "        \n",
    "        for ind_Nb_list in np.arange(len(Nb_list)):\n",
    "            Nb_tilde_hat = Nb_list[ind_Nb_list]\n",
    "            lambda_0_opt_hat_Nb_fixed = []\n",
    "            for ind_Na_list in np.arange(len(Na_list)):\n",
    "                Na_tilde_hat = Na_list[ind_Na_list]\n",
    "                # not a possible case\n",
    "                if Nb_tilde_hat+Na_tilde_hat>N:\n",
    "                    lambda_0_opt_hat_Nb_fixed.append(np.nan) # neutral for plots here\n",
    "                else:\n",
    "                    Psi_N_eps = Gamma_N_eps - delta_fun(la)*np.sum(w_k[N-Na_tilde_hat:N]) - delta_fun(lb)*np.sum(w_k[:Nb_tilde_hat])\n",
    "                    Upsilon_N = np.sum((q*w_k[Nb_tilde_hat:N-Na_tilde_hat])**(r/(r+j))) * ((r*beta)**(j/(r+j)))/j\n",
    "                    lambda_0_opt_hat = (Upsilon_N/Psi_N_eps)**((r+j)/j)\n",
    "                       \n",
    "                    if Psi_N_eps<0:\n",
    "                        lambda_0_opt_hat = np.nan\n",
    "                    else:\n",
    "                        if Na_tilde_hat>0:\n",
    "                            feas1 = (lambda_0_opt_hat - (r*beta)/(q*la**(r+j)*w_k[int(N-Na_tilde_hat)]))>=0\n",
    "                        else:\n",
    "                            feas1 = True\n",
    "                        if Nb_tilde_hat>0:\n",
    "                            feas2 = (lambda_0_opt_hat - (r*beta)/(q*lb**(r+j)*w_k[int(Nb_tilde_hat-1)]))<=0\n",
    "                        else:\n",
    "                            feas2 = True\n",
    "                        if Na_tilde_hat<N:\n",
    "                            feas3 = (lambda_0_opt_hat - (r*beta)/(q*la**(r+j)*w_k[int(N-Na_tilde_hat-1)]))<0\n",
    "                        else:\n",
    "                            feas3 = True\n",
    "                        if Nb_tilde_hat<N:\n",
    "                            feas4 = (lambda_0_opt_hat - (r*beta)/(q*lb**(r+j)*w_k[int(Nb_tilde_hat)]))>0\n",
    "                        else:\n",
    "                            feas4 = True\n",
    "\n",
    "                        feas = feas1 and feas2 and feas3 and feas4\n",
    "\n",
    "                        if feas:\n",
    "                            ok_counter+=1\n",
    "                            ok_NaNb.append((Na_tilde_hat,Nb_tilde_hat))\n",
    "                            if lambda_0_opt_hat > lambda_0_max:\n",
    "                                Na_best,Nb_best = Na_tilde_hat,Nb_tilde_hat\n",
    "                                lambda_0_max = lambda_0_opt_hat\n",
    "                            \n",
    "                    lambda_0_opt_hat_Nb_fixed.append(np.log10(lambda_0_opt_hat))\n",
    "                    \n",
    "            if Nb_tilde_hat==0:\n",
    "                Na_best0 = np.nanargmax(np.array(lambda_0_opt_hat_Nb_fixed))\n",
    "                lambda_0_max0 = lambda_0_opt_hat_Nb_fixed[Na_best0]\n",
    "            lambda_0_opt_hat_mesh.append(lambda_0_opt_hat_Nb_fixed)\n",
    "        \n",
    "        if display:\n",
    "            print('/!\\ KKT fulfilled at max hat_lambda_0^* for (Na,Nb) = ('+str(Na_best)+', '+str(Nb_best)+') /!\\ ')\n",
    "            print('total number of OK points in (Na,Nb) space: '+str(ok_counter))\n",
    "        \n",
    "        if display:\n",
    "        \n",
    "            fig2 = plt.figure(figsize=(9,6))\n",
    "            ax2 = plt.axes()\n",
    "            plt.grid()\n",
    "            cs2 = ax2.contourf(NA,NB,lambda_0_opt_hat_mesh,label='contour plot')\n",
    "            plt.scatter([Na_best],[Nb_best],color='red',label='optimal choice ($N_a,N_b$)')\n",
    "            plt.xlabel('$\\hat{N}_a$')\n",
    "            plt.ylabel('$\\hat{N}_b$')\n",
    "            plt.title('Visualization of $\\hat{\\lambda}_0^*$')\n",
    "            cbar2 = fig2.colorbar(cs2)\n",
    "            ax2.legend()\n",
    "            plt.savefig('lambdas0_double_impii_cont.pdf')\n",
    "\n",
    "            fig= plt.figure(figsize=(9,6))\n",
    "            ax = plt.axes(projection='3d')\n",
    "            cs1 = ax.contour3D(NA,NB,lambda_0_opt_hat_mesh, 50)\n",
    "            ax.set_xlabel('$\\hat{N}_a$')\n",
    "            ax.set_ylabel('$\\hat{N}_b$')\n",
    "            ax.set_zlabel('$log10(\\hat{\\lambda}_0^*)$')\n",
    "            ax.set_title('Visualization of $\\hat{\\lambda}_0^*$')\n",
    "            cbar1 = fig.colorbar(cs1)\n",
    "            plt.savefig('lambdas0_double_impi_surf.pdf')\n",
    "\n",
    "            plt.figure(figsize=(7,6))\n",
    "            plt.title('Visualization of $\\hat{\\lambda}_0^*$ at $N_b=0$ (with no $\\ell_b$)')\n",
    "            plt.xlabel('$\\hat{N}_a$')\n",
    "            plt.ylabel('$log10(\\hat{\\lambda}_0^*$)')\n",
    "            plt.grid()\n",
    "            plt.scatter(Na_list,np.array(lambda_0_opt_hat_mesh[0]),s=2.5)\n",
    "            plt.scatter([Na_best0],[lambda_0_max0],color='purple')\n",
    "            plt.legend(['$\\hat{\\lambda}_0^*$','optimal choice ($N_a$) at $N_b=0$']);\n",
    "            plt.savefig('lambdas0_single_impi_nb0.pdf')\n",
    "\n",
    "            plt.figure(figsize=(7,6))\n",
    "            plt.title('Visualization of $\\hat{\\lambda}_0^*$ at opt. $N_b$')\n",
    "            plt.xlabel('$\\hat{N}_a$')\n",
    "            plt.ylabel('$log10(\\hat{\\lambda}_0^*$)')\n",
    "            plt.grid()\n",
    "            plt.scatter(Na_list,np.array(lambda_0_opt_hat_mesh[int(Nb_best)]),s=2.5)\n",
    "            plt.scatter([Na_best],[np.log10(lambda_0_max)],color='red')\n",
    "            plt.legend(['$\\hat{\\lambda}_0^*$','optimal choice ($N_a,N_b$)']);\n",
    "            plt.savefig('lambdas0_single_impi_nbbest.pdf')\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        return Na_best,Nb_best,lambda_0_max,ok_NaNb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_ii_imp(N=151,L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,la=5e-7,lb=1e-3,beta=1,display=True):\n",
    "    N_list = np.arange(N+1)\n",
    "    delta_fun = lambda eta: (q/j)*eta**(j)\n",
    "    gamma_N,w_k,W_N = compute_serial_coeffs(N,L,mu,mode)\n",
    "    Gamma_N_eps = W_N*epsilon - (gamma_N*L*R**2)/2\n",
    "    check_feas = (Gamma_N_eps - np.sum(w_k)*delta_fun(la) >= 0) # check feasibility\n",
    "    if check_feas==False:\n",
    "        if display:\n",
    "            print(' => error infeasible || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "    else: # lin-search\n",
    "        if display:\n",
    "            print(' => experiment started || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "        Na_list = np.arange(N+1)\n",
    "        Nb_list = np.arange(N+1)\n",
    "        NA,NB = np.meshgrid(Na_list,Nb_list)\n",
    "        lambda_0_opt_hat_mesh = []\n",
    "        lambda_0_max = 0\n",
    "        Na_best,Nb_best = 0,0\n",
    "        Na_best0 = 0\n",
    "        lambda_0_max0 = 0\n",
    "        ok_counter = 0\n",
    "        ok_NaNb = []\n",
    "        \n",
    "        # clear version (not optimized though)\n",
    "        \n",
    "        for ind_Nb_list in np.arange(len(Nb_list)):\n",
    "            Nb_tilde_hat = Nb_list[ind_Nb_list]\n",
    "            lambda_0_opt_hat_Nb_fixed = []\n",
    "            for ind_Na_list in np.arange(len(Na_list)):\n",
    "                Na_tilde_hat = Na_list[ind_Na_list]\n",
    "                # not a possible case\n",
    "                if Nb_tilde_hat+Na_tilde_hat>N:\n",
    "                    lambda_0_opt_hat_Nb_fixed.append(np.nan) # neutral for plots here\n",
    "                else:\n",
    "                    Psi_N_eps = Gamma_N_eps - delta_fun(la)*np.sum(w_k[N-Na_tilde_hat:N]) - delta_fun(lb)*np.sum(w_k[:Nb_tilde_hat])\n",
    "                    Upsilon_N = np.sum((q*w_k[Nb_tilde_hat:N-Na_tilde_hat])**(0) * ((beta)**(1))/j)\n",
    "                    lambda_0_opt_hat = (Upsilon_N/Psi_N_eps)**(1)\n",
    "                    if Psi_N_eps<0:\n",
    "                        lambda_0_opt_hat = np.nan\n",
    "                    else:\n",
    "                        if Na_tilde_hat>0:\n",
    "                            feas1 = (lambda_0_opt_hat - (beta)/(q*la**(j)*w_k[int(N-Na_tilde_hat)]))>=0\n",
    "                        else:\n",
    "                            feas1 = True\n",
    "                        if Nb_tilde_hat>0:\n",
    "                            feas2 = (lambda_0_opt_hat - (beta)/(q*lb**(j)*w_k[int(Nb_tilde_hat-1)]))<=0\n",
    "                        else:\n",
    "                            feas2 = True\n",
    "                        if Na_tilde_hat<N:\n",
    "                            feas3 = (lambda_0_opt_hat - (beta)/(q*la**(j)*w_k[int(N-Na_tilde_hat-1)]))<0\n",
    "                        else:\n",
    "                            feas3 = True\n",
    "                        if Nb_tilde_hat<N:\n",
    "                            feas4 = (lambda_0_opt_hat - (beta)/(q*lb**(j)*w_k[int(Nb_tilde_hat)]))>0\n",
    "                        else:\n",
    "                            feas4 = True\n",
    "\n",
    "                        feas = feas1 and feas2 and feas3 and feas4\n",
    "\n",
    "                        if feas:\n",
    "                            ok_counter+=1\n",
    "                            ok_NaNb.append((Na_tilde_hat,Nb_tilde_hat))\n",
    "                            if lambda_0_opt_hat > lambda_0_max:\n",
    "                                Na_best,Nb_best = Na_tilde_hat,Nb_tilde_hat\n",
    "                                lambda_0_max = lambda_0_opt_hat\n",
    "\n",
    "                    lambda_0_opt_hat_Nb_fixed.append(np.log10(lambda_0_opt_hat))\n",
    "            if Nb_tilde_hat==0:\n",
    "                Na_best0 = np.nanargmax(np.array(lambda_0_opt_hat_Nb_fixed))\n",
    "                lambda_0_max0 = lambda_0_opt_hat_Nb_fixed[Na_best0]\n",
    "            lambda_0_opt_hat_mesh.append(lambda_0_opt_hat_Nb_fixed)\n",
    "            \n",
    "        \n",
    "        if display:\n",
    "            print('/!\\ KKT fulfilled at max hat_lambda_0^* for (Na,Nb) = ('+str(Na_best)+', '+str(Nb_best)+') /!\\ ')\n",
    "            print('total number of OK points in (Na,Nb) space: '+str(ok_counter))\n",
    "           \n",
    "        if display:\n",
    "            \n",
    "            fig2 = plt.figure(figsize=(9,6))\n",
    "            ax2 = plt.axes()\n",
    "            plt.grid()\n",
    "            cs2 = ax2.contourf(NA,NB,lambda_0_opt_hat_mesh,label='contour plot')\n",
    "            plt.scatter([Na_best],[Nb_best],color='red',label='optimal choice ($N_a,N_b$)')\n",
    "            plt.xlabel('$\\hat{N}_a$')\n",
    "            plt.ylabel('$\\hat{N}_b$')\n",
    "            plt.title('Visualization of $\\hat{\\lambda}_0^*$')\n",
    "            cbar2 = fig2.colorbar(cs2)\n",
    "            ax2.legend()\n",
    "            plt.savefig('lambdas0_double_impii_cont.pdf')\n",
    "\n",
    "            fig= plt.figure(figsize=(9,6))\n",
    "            ax = plt.axes(projection='3d')\n",
    "            cs1 = ax.contour3D(NA,NB,lambda_0_opt_hat_mesh, 50)\n",
    "            ax.set_xlabel('$\\hat{N}_a$')\n",
    "            ax.set_ylabel('$\\hat{N}_b$')\n",
    "            ax.set_zlabel('$log10(\\hat{\\lambda}_0^*)$')\n",
    "            ax.set_title('Visualization of $\\hat{\\lambda}_0^*$')\n",
    "            cbar1 = fig.colorbar(cs1)\n",
    "            plt.savefig('lambdas0_double_impii_surf.pdf')\n",
    "\n",
    "            plt.figure(figsize=(7,6))\n",
    "            plt.title('Visualization of $\\hat{\\lambda}_0^*$ at $N_b=0$ (with no $\\ell_b$)')\n",
    "            plt.xlabel('$\\hat{N}_a$')\n",
    "            plt.ylabel('$log10(\\hat{\\lambda}_0^*$)')\n",
    "            plt.grid()\n",
    "            plt.scatter(Na_list,np.array(lambda_0_opt_hat_mesh[0]),s=2.5)\n",
    "            plt.scatter([Na_best0],[lambda_0_max0],color='purple')\n",
    "            plt.legend(['$\\hat{\\lambda}_0^*$','optimal choice ($N_a$) at $N_b=0$']);\n",
    "            plt.savefig('lambdas0_single_impii_nb0.pdf')\n",
    "\n",
    "            plt.figure(figsize=(7,6))\n",
    "            plt.title('Visualization of $\\hat{\\lambda}_0^*$ at opt. $N_b$')\n",
    "            plt.xlabel('$\\hat{N}_a$')\n",
    "            plt.ylabel('$log10(\\hat{\\lambda}_0^*$)')\n",
    "            plt.grid()\n",
    "            plt.scatter(Na_list,np.array(lambda_0_opt_hat_mesh[int(Nb_best)]),s=2.5)\n",
    "            plt.scatter([Na_best],[np.log10(lambda_0_max)],color='red')\n",
    "            plt.legend(['$\\hat{\\lambda}_0^*$','optimal choice ($N_a,N_b$)']);\n",
    "            plt.savefig('lambdas0_single_impii_nbbest.pdf')\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        return Na_best,Nb_best,lambda_0_max,ok_NaNb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kkt_i_imp(N=151,L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,r=1,la=5e-7,lb=1e-3,beta=1,display=True):\n",
    "   \n",
    "    N_list = np.arange(N+1)\n",
    "    delta_fun = lambda eta: (q/j)*eta**(j)\n",
    "    gamma_N,w_k,W_N = compute_serial_coeffs(N,L,mu,mode)\n",
    "    Gamma_N_eps = W_N*epsilon - (gamma_N*L*R**2)/2\n",
    "    check_feas = (Gamma_N_eps - np.sum(w_k)*delta_fun(la) >= 0) # check feasibility\n",
    "   \n",
    "    if check_feas==False:\n",
    "       \n",
    "        if display:\n",
    "            print(' => error infeasible || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "    \n",
    "    else: # lin-search\n",
    "       \n",
    "        if display:\n",
    "            print(' => experiment started || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "        \n",
    "        Na_list = np.arange(N+1)\n",
    "        if lb == widget_lb.max:\n",
    "            Nb_list = np.array([0])\n",
    "        else:\n",
    "            Nb_list = np.arange(N+1)\n",
    "        Nb_bound = np.max(Nb_list)\n",
    "        ind_Nb_list = int(0)\n",
    "        ind_Na_list = int(0)\n",
    "        \n",
    "        # clear version (not optimized though)\n",
    "        \n",
    "        while ind_Nb_list <= Nb_bound:\n",
    "            Nb_tilde_hat = Nb_list[ind_Nb_list]\n",
    "            ind_Na_list = int(0)\n",
    "            while ind_Na_list <= N:\n",
    "                Na_tilde_hat = Na_list[ind_Na_list]\n",
    "                if Nb_tilde_hat+Na_tilde_hat<=N:\n",
    "                    Psi_N_eps = Gamma_N_eps - delta_fun(la)*np.sum(w_k[N-Na_tilde_hat:N]) - delta_fun(lb)*np.sum(w_k[:Nb_tilde_hat])\n",
    "                    Upsilon_N = np.sum((q*w_k[Nb_tilde_hat:N-Na_tilde_hat])**(r/(r+j))) * ((r*beta)**(j/(r+j)))/j\n",
    "                    lambda_0_opt_hat = (Upsilon_N/Psi_N_eps)**((r+j)/j)\n",
    "                    if Psi_N_eps<0:\n",
    "                        feas = False\n",
    "                    else:\n",
    "                        if Na_tilde_hat>0:\n",
    "                            feas1 = (lambda_0_opt_hat - (r*beta)/(q*la**(r+j)*w_k[int(N-Na_tilde_hat)]))>=0\n",
    "                        else:\n",
    "                            feas1 = True\n",
    "                        if Nb_tilde_hat>0:\n",
    "                            feas2 = (lambda_0_opt_hat - (r*beta)/(q*lb**(r+j)*w_k[int(Nb_tilde_hat-1)]))<=0\n",
    "                        else:\n",
    "                            feas2 = True\n",
    "                        if Na_tilde_hat<N:\n",
    "                            feas3 = (lambda_0_opt_hat - (r*beta)/(q*la**(r+j)*w_k[int(N-Na_tilde_hat-1)]))<0\n",
    "                        else:\n",
    "                            feas3 = True\n",
    "                        if Nb_tilde_hat<N and (lb!=widget_lb.max):\n",
    "                            feas4 = (lambda_0_opt_hat - (r*beta)/(q*lb**(r+j)*w_k[int(Nb_tilde_hat)]))>0\n",
    "                        else:\n",
    "                            feas4 = True\n",
    "\n",
    "                        feas = feas1 and feas2 and feas3 and feas4\n",
    "                else:\n",
    "                    feas = False\n",
    "                    \n",
    "                if feas:\n",
    "                    Na_best = Na_tilde_hat\n",
    "                    Nb_best = Nb_tilde_hat\n",
    "                    lambda_0_max = lambda_0_opt_hat\n",
    "                    ind_Nb_list = N+1\n",
    "                    ind_Na_list = N+1\n",
    "                else:\n",
    "                    ind_Na_list += int(1)\n",
    "            ind_Nb_list += int(1)\n",
    "        \n",
    "        if display:\n",
    "            print('/!\\ KKT fulfilled for (Na,Nb) = ('+str(Na_best)+', '+str(Nb_best)+') /!\\ ')\n",
    "           \n",
    "        return Na_best,Nb_best,lambda_0_max,w_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kkt_ii_imp(N=151,L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,la=5e-7,lb=1e-3,beta=1,display=True):\n",
    "   \n",
    "    N_list = np.arange(N+1)\n",
    "    delta_fun = lambda eta: (q/j)*eta**(j)\n",
    "    gamma_N,w_k,W_N = compute_serial_coeffs(N,L,mu,mode)\n",
    "    Gamma_N_eps = W_N*epsilon - (gamma_N*L*R**2)/2\n",
    "    check_feas = (Gamma_N_eps - np.sum(w_k)*delta_fun(la) >= 0) # check feasibility\n",
    "   \n",
    "    if check_feas==False:\n",
    "       \n",
    "        if display:\n",
    "            print(' => error infeasible || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "    \n",
    "    else: # lin-search\n",
    "       \n",
    "        if display:\n",
    "            print(' => experiment started || '+'Gamma_N_eps = '+str(Gamma_N_eps)+' , (sum_k w_k) delta(la) = '+str(np.sum(w_k)*delta_fun(la)))\n",
    "        \n",
    "        Na_list = np.arange(N+1)\n",
    "        if lb == widget_lb.max:\n",
    "            Nb_list = np.array([0])\n",
    "        else:\n",
    "            Nb_list = np.arange(N+1)\n",
    "        Nb_bound = np.max(Nb_list)\n",
    "        ind_Nb_list = int(0)\n",
    "        ind_Na_list = int(0)\n",
    "        \n",
    "        # clear version (not optimized though)\n",
    "        \n",
    "        while ind_Nb_list <= Nb_bound:\n",
    "            Nb_tilde_hat = Nb_list[ind_Nb_list]\n",
    "            ind_Na_list = int(0)\n",
    "            while ind_Na_list <= N:\n",
    "                Na_tilde_hat = Na_list[ind_Na_list]\n",
    "                if Nb_tilde_hat+Na_tilde_hat<=N:\n",
    "                    Psi_N_eps = Gamma_N_eps - delta_fun(la)*np.sum(w_k[N-Na_tilde_hat:N]) - delta_fun(lb)*np.sum(w_k[:Nb_tilde_hat])\n",
    "                    Upsilon_N = np.sum((q*w_k[Nb_tilde_hat:N-Na_tilde_hat])**(0) * ((beta)**(1))/j)\n",
    "                    lambda_0_opt_hat = (Upsilon_N/Psi_N_eps)**(1)\n",
    "                    if Psi_N_eps<0:\n",
    "                        feas = False\n",
    "                    else:\n",
    "                        if Na_tilde_hat>0:\n",
    "                            feas1 = (lambda_0_opt_hat - (beta)/(q*la**(j)*w_k[int(N-Na_tilde_hat)]))>=0\n",
    "                        else:\n",
    "                            feas1 = True\n",
    "                        if Nb_tilde_hat>0:\n",
    "                            feas2 = (lambda_0_opt_hat - (beta)/(q*lb**(j)*w_k[int(Nb_tilde_hat-1)]))<=0\n",
    "                        else:\n",
    "                            feas2 = True\n",
    "                        if Na_tilde_hat<N:\n",
    "                            feas3 = (lambda_0_opt_hat - (beta)/(q*la**(j)*w_k[int(N-Na_tilde_hat-1)]))<0\n",
    "                        else:\n",
    "                            feas3 = True\n",
    "                        if Nb_tilde_hat<N and (lb!=widget_lb.max):\n",
    "                            feas4 = (lambda_0_opt_hat - (beta)/(q*lb**(j)*w_k[int(Nb_tilde_hat)]))>0\n",
    "                        else:\n",
    "                            feas4 = True\n",
    "\n",
    "                        feas = feas1 and feas2 and feas3 and feas4\n",
    "                else:\n",
    "                    feas = False\n",
    "                    \n",
    "                if feas:\n",
    "                    Na_best = Na_tilde_hat\n",
    "                    Nb_best = Nb_tilde_hat\n",
    "                    lambda_0_max = lambda_0_opt_hat\n",
    "                    ind_Nb_list = N+1\n",
    "                    ind_Na_list = N+1\n",
    "                else:\n",
    "                    ind_Na_list += int(1)\n",
    "            ind_Nb_list += int(1)\n",
    "        \n",
    "        if display:\n",
    "            print('/!\\ KKT fulfilled for (Na,Nb) = ('+str(Na_best)+', '+str(Nb_best)+') /!\\ ')\n",
    "           \n",
    "        return Na_best,Nb_best,lambda_0_max,w_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_opt_schedule_i(w_k,r,beta,lambda0,j,la,lb,Na,Nb,q):\n",
    "    basis = (r*beta/(lambda0*w_k*q))**(1/(r+j))\n",
    "    basis[:int(Nb)] = lb\n",
    "    basis[int(len(basis)-Na):] = la\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_opt_schedule_ii(w_k,beta,lambda0,j,la,lb,Na,Nb,q):\n",
    "    basis = (beta/(lambda0*w_k*q))**(1/(j))\n",
    "    basis[:int(Nb)] = lb\n",
    "    basis[int(len(basis)-Na):] = la\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_kkt_i_imp(K=1000,L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,r=1,la=5e-7,lb=1e-3,beta=1):\n",
    "    \n",
    "    multiplicator = 2\n",
    "    \n",
    "    N_min = int(N_lower(L,mu,mode,epsilon,R,j,q,la,False))\n",
    "    N_max = int(multiplicator*N_min)\n",
    "    \n",
    "    N_list = np.linspace(N_min,N_max,(N_max-N_min)+1)\n",
    "    \n",
    "    cost_fun = lambda eta: K*len(eta) + np.sum(beta/eta**r)\n",
    "    \n",
    "    Na_list = []\n",
    "    Nb_list = []\n",
    "    costs_list = []\n",
    "    \n",
    "    best_N = N_min\n",
    "    best_Na,best_Nb = 0,0\n",
    "    best_cost = np.inf\n",
    "    \n",
    "    for elem in N_list:\n",
    "        N = int(elem)\n",
    "        Na,Nb,lambda0,w_k = kkt_i_imp(N,L,mu,mode,epsilon,R,j,q,r,la,lb,beta,display=False)\n",
    "        Na_list.append(Na)\n",
    "        Nb_list.append(Nb)\n",
    "        eta_opt = retrieve_opt_schedule_i(w_k,r,beta,lambda0,j,la,lb,Na,Nb,q)\n",
    "        try_cost = cost_fun(eta_opt)\n",
    "        costs_list.append(try_cost)\n",
    "        if try_cost<best_cost:\n",
    "            best_cost = try_cost\n",
    "            best_N = N\n",
    "            best_Na,best_Nb = Na,Nb\n",
    "    \n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.title('Visualization of $MP^*(N)$ with $N$')\n",
    "    plt.grid()\n",
    "    plt.ylabel('optimal costs')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.plot(N_list,costs_list,color='blue')\n",
    "    plt.scatter([best_N],[best_cost],color='yellow')\n",
    "    plt.legend(['$MP^*(N)$','$MP^*(N^*)$'])\n",
    "    \n",
    "    plt.figure(figsize=(9,6))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    plt.title('Visualization of $MP^*(N)$ optimal together with optimal ($N_a,N_b$)')\n",
    "    ax.plot3D(Na_list,Nb_list,costs_list)\n",
    "    plt.xlabel('$N_a$')\n",
    "    plt.ylabel('$N_b$')\n",
    "    plt.legend(['optimal choice of ($N_a,N_b$)'],loc=10)\n",
    "    \n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('Visualization of $MP^*(N)$ optimal together with optimal ($N_a,N_b$)')\n",
    "    ax.set_xlabel('$N_a$')\n",
    "    ax.set_ylabel('$N_b$')\n",
    "    ax.grid(True,linestyle='-',color='0.75')\n",
    "    ax.scatter(Na_list,Nb_list,s=10,c=costs_list);\n",
    "    ax.scatter([best_Na],[best_Nb],s=20,c=[best_cost])\n",
    "    plt.legend(['optimal ($N_a,N_b$) (N)','optimal ($N_a,N_b$) (N^*)'])\n",
    "    \n",
    "    gamma_N_begin,_,W_N_begin = compute_serial_coeffs(N_min,L,mu,mode)\n",
    "    conv_term_begin = (gamma_N_begin*L*R**2)/(2*W_N_begin)\n",
    "    error_term_begin = epsilon-conv_term_begin\n",
    "    partitioner(N_min,conv_term_begin,error_term_begin)\n",
    "    \n",
    "    gamma_N_opt,_,W_N_opt = compute_serial_coeffs(best_N,L,mu,mode)\n",
    "    conv_term_opt = (gamma_N_opt*L*R**2)/(2*W_N_opt)\n",
    "    error_term_opt = epsilon-conv_term_opt\n",
    "    partitioner(best_N,conv_term_opt,error_term_opt)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_kkt_ii_imp(K=1000,L=10,mu=0.1,mode='FGD',epsilon=1e-5,R=10,j=1,q=1,la=5e-7,lb=1e-3,beta=1):\n",
    "    \n",
    "    multiplicator = 2\n",
    "    \n",
    "    N_min = int(N_lower(L,mu,mode,epsilon,R,j,q,la,False))\n",
    "    N_max = int(multiplicator*N_min)\n",
    "    \n",
    "    N_list = np.linspace(N_min,N_max,(N_max-N_min)+1)\n",
    "    \n",
    "    cost_fun = lambda eta: K*len(eta) + np.sum(beta/eta**r)\n",
    "    \n",
    "    Na_list = []\n",
    "    Nb_list = []\n",
    "    costs_list = []\n",
    "    \n",
    "    best_N = N_min\n",
    "    best_Na,best_Nb = 0,0\n",
    "    best_cost = np.inf\n",
    "    \n",
    "    for elem in N_list:\n",
    "        N = int(elem)\n",
    "        Na,Nb,lambda0,w_k = kkt_ii_imp(N,L,mu,mode,epsilon,R,j,q,la,lb,beta,display=False)\n",
    "        Na_list.append(Na)\n",
    "        Nb_list.append(Nb)\n",
    "        eta_opt = retrieve_opt_schedule_ii(w_k,beta,lambda0,j,la,lb,Na,Nb,q)\n",
    "        try_cost = cost_fun(eta_opt)\n",
    "        costs_list.append(try_cost)\n",
    "        if try_cost<best_cost:\n",
    "            best_cost = try_cost\n",
    "            best_N = N\n",
    "            best_Na,best_Nb = Na,Nb\n",
    "    \n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.title('Visualization of $MP^*(N)$ with $N$')\n",
    "    plt.grid()\n",
    "    plt.ylabel('optimal costs')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.plot(N_list,costs_list,color='blue')\n",
    "    plt.scatter([best_N],[best_cost],color='yellow')\n",
    "    plt.legend(['$MP^*(N)$','$MP^*(N^*)$'])\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(9,6))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    plt.title('Visualization of $MP^*(N)$ optimal together with optimal ($N_a,N_b$)')\n",
    "    ax.plot3D(Na_list,Nb_list,costs_list)\n",
    "    plt.xlabel('$N_a$')\n",
    "    plt.ylabel('$N_b$')\n",
    "    plt.legend(['optimal choice of ($N_a,N_b$)'],loc=10)\n",
    "    \n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('Visualization of $MP^*(N)$ optimal together with optimal ($N_a,N_b$)')\n",
    "    ax.set_xlabel('$N_a$')\n",
    "    ax.set_ylabel('$N_b$')\n",
    "    ax.grid(True,linestyle='-',color='0.75')\n",
    "    ax.scatter(Na_list,Nb_list,s=10,c=costs_list);\n",
    "    ax.scatter([best_Na],[best_Nb],s=20,c=[best_cost])\n",
    "    plt.legend(['optimal ($N_a,N_b$) (N)','optimal ($N_a,N_b$) (N^*)'])\n",
    "    \n",
    "    gamma_N_begin,_,W_N_begin = compute_serial_coeffs(N_min,L,mu,mode)\n",
    "    conv_term_begin = (gamma_N_begin*L*R**2)/(2*W_N_begin)\n",
    "    error_term_begin = epsilon-conv_term_begin\n",
    "    partitioner(N_min,conv_term_begin,error_term_begin)\n",
    "    \n",
    "    gamma_N_opt,_,W_N_opt = compute_serial_coeffs(best_N,L,mu,mode)\n",
    "    conv_term_opt = (gamma_N_opt*L*R**2)/(2*W_N_opt)\n",
    "    error_term_opt = epsilon-conv_term_opt\n",
    "    partitioner(best_N,conv_term_opt,error_term_opt)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda0_base_experiment():\n",
    "\n",
    "    if Instance.cost_model=='inv_prop':\n",
    "        experiment_i_imp(Instance.N,Problem.L,Problem.mu,Instance.met,Instance.epsilon,Instance.R,Instance.j,\\\n",
    "                         Instance.q,Instance.r,Instance.la,Instance.lb,Instance.beta,True);\n",
    "    else:\n",
    "        experiment_ii_imp(Instance.N,Problem.L,Problem.mu,Instance.met,Instance.epsilon,Instance.R,Instance.j,Instance.q,\\\n",
    "                         Instance.la,Instance.lb,Instance.beta,True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "button2 = widgets.Button(description=\"Load Small Exp.\")\n",
    "output2 = widgets.Output()\n",
    "\n",
    "display(button2, output2)\n",
    "\n",
    "def on_button_clicked2(b):\n",
    "    with output2:\n",
    "        clear_output()\n",
    "        lambda0_base_experiment()\n",
    "\n",
    "button2.on_click(on_button_clicked2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda0_intensive_experiment():\n",
    "    \n",
    "    if Instance.cost_model=='inv_prop':\n",
    "        multi_kkt_i_imp(Instance.K,Problem.L,Problem.mu,Instance.met,Instance.epsilon,Instance.R,Instance.j,Instance.q,Instance.r,\\\n",
    "                         Instance.la,Instance.lb,Instance.beta);\n",
    "    else:\n",
    "        multi_kkt_ii_imp(Instance.K,Problem.L,Problem.mu,Instance.met,Instance.epsilon,Instance.R,Instance.j,Instance.q,\\\n",
    "                         Instance.la,Instance.lb,Instance.beta); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button3 = widgets.Button(description=\"Load Large Exp.\")\n",
    "output3 = widgets.Output()\n",
    "\n",
    "display(button3, output3)\n",
    "\n",
    "def on_button_clicked3(b):\n",
    "    with output3:\n",
    "        clear_output()\n",
    "        lambda0_intensive_experiment()\n",
    "\n",
    "button3.on_click(on_button_clicked3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KKT - conditions solving at given $N$\n",
    "-------------------------------------------------------\n",
    "\n",
    "Please refer to the article for the derivation of the optimality conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#experiment_i_imp(N=150,L=10,mu=0.1,epsilon=0.53e-5,mode='FGD',la=1e-8,lb=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#experiment_ii_imp(N=150,L=10,mu=0.1,epsilon=0.53e-5,mode='FGD',la=1e-8,lb=1e-5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
